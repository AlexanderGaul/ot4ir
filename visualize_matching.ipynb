{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sklearn.preprocessing as skprep\n",
    "\n",
    "import ot\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "from torch.utils.model_zoo import load_url\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirtorch.networks.imageretrievalnet import init_network, extract_interest_points_mac\n",
    "from cirtorch.datasets.datahelpers import cid2filename\n",
    "from cirtorch.datasets.testdataset import configdataset\n",
    "from cirtorch.utils.download import download_train, download_test\n",
    "from cirtorch.utils.whiten import whitenlearn, whitenapply\n",
    "from cirtorch.utils.evaluate import compute_map_and_print\n",
    "from cirtorch.utils.general import get_data_root, htime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'oxford5k'\n",
    "network_path = 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/rSfM120k-tl-resnet50-gem-w-97bf910.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/rSfM120k-tl-resnet50-gem-w-97bf910.pth\" to /home/alexander/Documents/studies/20_ss/guided_research/code/ot4ir/data/networks/rSfM120k-tl-resnet50-gem-w-97bf910.pth\n",
      "100%|██████████| 106M/106M [00:02<00:00, 51.5MB/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ImageRetrievalNet:\n\tMissing key(s) in state_dict: \"att.conv1.weight\", \"att.conv1.bias\", \"att.conv2.weight\", \"att.conv2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-886f3a3d2b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnet_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pretrained'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m normalize = transforms.Normalize(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ImageRetrievalNet:\n\tMissing key(s) in state_dict: \"att.conv1.weight\", \"att.conv1.bias\", \"att.conv2.weight\", \"att.conv2.bias\". "
     ]
    }
   ],
   "source": [
    "state = load_url(network_path, model_dir=os.path.join(get_data_root(), 'networks'))\n",
    "net_params = {}\n",
    "net_params['architecture'] = state['meta']['architecture']\n",
    "net_params['pooling'] = state['meta']['pooling']\n",
    "net_params['local_whitening'] = state['meta'].get('local_whitening', False)\n",
    "net_params['regional'] = state['meta'].get('regional', False)\n",
    "net_params['whitening'] = state['meta'].get('whitening', False)\n",
    "net_params['mean'] = state['meta']['mean']\n",
    "net_params['std'] = state['meta']['std']\n",
    "net_params['pretrained'] = False\n",
    "net = init_network(net_params)\n",
    "net.load_state_dict(state['state_dict'])\n",
    "net.eval()\n",
    "normalize = transforms.Normalize(\n",
    "    mean=net.meta['mean'],\n",
    "    std=net.meta['std']\n",
    ")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches(ax, image1, image2, keypoints1, keypoints2, matches,\n",
    "                 keypoints_color='k', matches_color=None, only_matches=False,\n",
    "                 alignment='horizontal'):\n",
    "\n",
    "    new_shape1 = list(image1.shape)\n",
    "    new_shape2 = list(image2.shape)\n",
    "\n",
    "    if image1.shape[0] < image2.shape[0]:\n",
    "        new_shape1[0] = image2.shape[0]\n",
    "    elif image1.shape[0] > image2.shape[0]:\n",
    "        new_shape2[0] = image1.shape[0]\n",
    "\n",
    "    if image1.shape[1] < image2.shape[1]:\n",
    "        new_shape1[1] = image2.shape[1]\n",
    "    elif image1.shape[1] > image2.shape[1]:\n",
    "        new_shape2[1] = image1.shape[1]\n",
    "\n",
    "    if new_shape1 != image1.shape:\n",
    "        new_image1 = np.zeros(new_shape1, dtype=image1.dtype)\n",
    "        new_image1[:image1.shape[0], :image1.shape[1]] = image1\n",
    "        image1 = new_image1\n",
    "\n",
    "    if new_shape2 != image2.shape:\n",
    "        new_image2 = np.zeros(new_shape2, dtype=image2.dtype)\n",
    "        new_image2[:image2.shape[0], :image2.shape[1]] = image2\n",
    "        image2 = new_image2\n",
    "\n",
    "    offset = np.array(image1.shape)\n",
    "    if alignment == 'horizontal':\n",
    "        image = np.concatenate([image1, image2], axis=1)\n",
    "        offset[0] = 0\n",
    "    elif alignment == 'vertical':\n",
    "        image = np.concatenate([image1, image2], axis=0)\n",
    "        offset[1] = 0\n",
    "    else:\n",
    "        mesg = (\"plot_matches accepts either 'horizontal' or 'vertical' for \"\n",
    "                \"alignment, but '{}' was given. See \"\n",
    "                \"https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.plot_matches \"  # noqa\n",
    "                \"for details.\").format(alignment)\n",
    "        raise ValueError(mesg)\n",
    "\n",
    "    ax.imshow(image, interpolation='nearest', cmap='gray')\n",
    "    ax.axis((0, image1.shape[1] + offset[1], image1.shape[0] + offset[0], 0))\n",
    "\n",
    "    for i in range(matches.shape[0]):\n",
    "        idx1 = matches[i, 0]\n",
    "        idx2 = matches[i, 1]\n",
    "\n",
    "        if matches_color is None:\n",
    "            color = np.random.rand(3)\n",
    "        else:\n",
    "            color = matches_color\n",
    "\n",
    "        ax.plot((keypoints1[idx1, 1], keypoints2[idx2, 1] + offset[1]),\n",
    "                (keypoints1[idx1, 0], keypoints2[idx2, 0] + offset[0]),\n",
    "                '-', color=color, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mutual matches ##\n",
    "def mutual_max(P) :\n",
    "    max0, max1 = P.max(1), P.max(0)\n",
    "    indices0, indices1 = max0.indices, max1.indices\n",
    "    mutual0 = torch.LongTensor(range(indices0.shape[0])) == indices1.gather(0, indices0)\n",
    "    mutual1 = torch.LongTensor(range(indices1.shape[0])) == indices0.gather(0, indices1)\n",
    "    zero = P.new_tensor(0)\n",
    "    mscores0 = torch.where(mutual0, max0.values.exp(), zero)\n",
    "    mscores1 = torch.where(mutual1, mscores0.gather(0, indices1), zero)\n",
    "\n",
    "    valid0 = mutual0 & (mscores0 > 0)\n",
    "    valid1 = mutual1 & valid0.gather(1, indices1)\n",
    "\n",
    "    indices0 = torch.where(valid0, indices0, indices0.new_tensor(-1))\n",
    "    indices1 = torch.where(valid1, indices1, indices1.new_tensor(-1))\n",
    "\n",
    "    # make norm\n",
    "    return indices0, indices1, mscores0, mscores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-aa2fdcdd3a4e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-aa2fdcdd3a4e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    query =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "q_idx =  \n",
    "p_idx =\n",
    "n_idx = \n",
    "\n",
    "qimage = [ cfg['qim_fname'](cfg, i) ]\n",
    "qgnd_images = [ cfg['im_fname'](cfg,j) for j in cfg['gnd'][i]['ok'][:num_gnd] ]\n",
    "qgndj_images = [ cfg['im_fname'](cfg,j) for j in cfg['gnd'][i]['junk'][:num_gndj] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_descriptors, q_locations, q_scores = extract_interest_points_mac(net, qimage, args.image_size, transform, ms=ms, msp=msp)\n",
    "qgnd_descriptors, qgnd_locations, qgnd_scores = extract_interest_points_mac(net, qgnd_images, args.image_size, transform, ms=ms, msp=msp)\n",
    "qgndj_descriptors, qgndj_locations, qgndj_scores = extract_interest_points_mac(net, qgndj_images, args.image_size, transform, ms=ms, msp=msp)\n",
    "\n",
    "\n",
    "q_descriptors = q_descriptors.numpy()\n",
    "q_locations = q_locations.numpy()\n",
    "\n",
    "qgnd_descriptors = qgnd_descriptors.numpy()\n",
    "qgnd_locations = qgnd_locations.numpy()\n",
    "\n",
    "qgndj_descriptors = qgndj_descriptors.numpy()\n",
    "qgndj_locations = qgndj_locations.numpy()\n",
    "\n",
    "q_scores = q_scores.numpy()\n",
    "qgnd_scores = qgnd_scores.numpy()\n",
    "qgndj_scores = qgndj_scores.numpy()\n",
    "\n",
    "## OT\n",
    "\n",
    "P = ot.sinkhorn(a, b, M, 0.01, numItermax=2000)\n",
    "\n",
    "ind_0, ind_1, _, _ = mutual_max(P)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_matches(\n",
    "    ax,\n",
    "    img_1,\n",
    "    img_2,\n",
    "    loc_1,\n",
    "    loc_2,\n",
    "    max_match,\n",
    "    matches_color='b')\n",
    "ax.axis('off')\n",
    "ax.set_title('OT correspondences')\n",
    "plt.savefig('ot_' + str(loc_scale) + '_' + img_1_name + '_' + img_2_name + '_' + args.output_image, dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
